<<VM's>>
          - alert: OutOfMemory
            expr: job:node_memory_MemFree{job="prodNodes"} / job:node_memory_MemTotal{job="prodNodes"} * 100 < 10
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Out of memory (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  Node memory is filling up (< 10%% left)\\n    VALUE = {{ $value }}\\n    Project: {{ $labels.project }}\\n    DTAP: {{ $labels.type }}\\n \"" }}
          - alert: UnusualNetworkThroughputIn
            expr: sum by (instance) (irate(job:node_network_receive_bytes{job="prodNodes"}[2m])) / 1024 / 1024 > 100
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Unusual network throughput in (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  Host network interfaces are probably receiving too much data (> 100 MB/s)\\n    VALUE = {{ $value }}\\n    Project: {{ $labels.project }}\\n    DTAP: {{ $labels.type }}\\n \"" }}
          - alert: UnusualNetworkThroughputOut
            expr: sum by (instance) (irate(job:node_network_transmit_bytes{job="prodNodes"}[2m])) / 1024 / 1024 > 100
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Unusual network throughput out (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  Host network interfaces are probably sending too much data (> 100 MB/s)\\n    VALUE = {{ $value }}\\n    Project: {{ $labels.project }}\\n    DTAP: {{ $labels.type }}\\n \"" }}
          - alert: UnusualDiskReadRate
            expr: sum by (instance) (irate(job:node_disk_read_bytes{job="prodNodes"}[2m])) / 1024 / 1024 > 50
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Unusual disk read rate (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  Disk is probably reading too much data (> 50 MB/s)\\n    VALUE = {{ $value }}\\n    Project: {{ $labels.project }}\\n    DTAP: {{ $labels.type }}\\n \"" }}
          - alert: UnusualDiskWriteRate
            expr: sum by (instance) (irate(job:node_disk_written_bytes{job="prodNodes"}[2m])) / 1024 / 1024 > 50
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Unusual disk write rate (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  Disk is probably writing too much data (> 50 MB/s)\\n    VALUE = {{ $value }}\\n    Project: {{ $labels.project }}\\n    DTAP: {{ $labels.type }}\\n \"" }}
          - alert: OutOfDiskSpace
            expr: job:node_filesystem_free_bytes{job="prodNodes", mountpoint ="/rootfs"} / job:node_filesystem_size_bytes{job="prodNodes", mountpoint ="/rootfs"} * 100 < 10
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Out of disk space (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  Disk is almost full (< 10%% left)\\n    VALUE = {{ $value }}\\n    Project: {{ $labels.project }}\\n    DTAP: {{ $labels.type }}\\n \"" }}
          - alert: OutOfInodes
            expr: job:node_filesystem_files_free{job="prodNodes", mountpoint ="/rootfs"} / job:node_filesystem_files{job="prodNodes", mountpoint ="/rootfs"} * 100 < 10
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Out of inodes (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  Disk is almost running out of available inodes (< 10%% left)\\n    VALUE = {{ $value }}\\n    Project: {{ $labels.project }}\\n    DTAP: {{ $labels.type }}\\n \"" }}
          - alert: UnusualDiskReadLatency
            expr: rate(job:node_disk_read_time_ms{job="prodNodes"}[1m]) / rate(job:node_disk_reads_completed{job="prodNodes"}[1m]) > 100
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Unusual disk read latency (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  Disk latency is growing (read operations > 100ms)\\n    VALUE = {{ $value }}\\n    Project: {{ $labels.project }}\\n    DTAP: {{ $labels.type }}\\n \"" }}
          - alert: UnusualDiskWriteLatency
            expr: rate(job:node_disk_write_time_ms{job="prodNodes"}[1m]) / rate(job:node_disk_writes_completed{job="prodNodes"}[1m]) > 100
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Unusual disk write latency (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  Disk latency is growing (write operations > 100ms)\\n    VALUE = {{ $value }}\\n    Project: {{ $labels.project }}\\n    DTAP: {{ $labels.type }}\\n \"" }}
          - alert: HighCpuLoad
            expr: 100 - (avg by(instance) (irate(job:node_cpu{job="prodNodes", mode="idle"}[5m])) * 100) > 80
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"High CPU load (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  CPU load is > 80%%\\n    VALUE = {{ $value }}\\n    Project: {{ $labels.project }}\\n    DTAP: {{ $labels.type }}\\n \"" }}
          - alert: ContextSwitching
            expr: rate(job:node_context_switches{job="prodNodes"}[5m]) > 1000
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Context switching (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  Context switching is growing on node (> 1000 / s)\\n    VALUE = {{ $value }}\\n    Project: {{ $labels.project }}\\n    DTAP: {{ $labels.type }}\\n \"" }}
          - alert: SwapIsFillingUp
            expr: (1 - (job:node_memory_SwapFree{job="prodNodes"} / job:node_memory_SwapTotal{job="prodNodes"})) * 100 > 80
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Swap is filling up (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  Swap is filling up ( > 80%% )\\n    VALUE = {{ $value }}\\n    Project: {{ $labels.project }}\\n    DTAP: {{ $labels.type }}\\n \"" }}
          

<<Kubernetes>>
          - alert: PodOOMKilled
            expr: kube_pod_container_status_terminated_reason{reason='OOMKilled'} == 1
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"OOMKilled\"" }}
              description: {{ printf "\"  Pod {{$labels.container}} in namespace {{$labels.namespace}} got OOMKilled.\\n \"" }}
          - alert: KubernetesMemorypressure
            expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Kubernetes MemoryPressure (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  {{ $labels.node }} has MemoryPressure condition\\n    VALUE = {{ $value }}\\n \"" }}
          - alert: KubernetesDiskpressure
            expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Kubernetes DiskPressure (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  {{ $labels.node }} has DiskPressure condition\\n    Instance: {{ $labels.instance }}\\n \"" }}
          - alert: KubernetesOutofdisk
            expr: kube_node_status_condition{condition="OutOfDisk",status="true"} == 1
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Kubernetes OutOfDisk (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  {{ $labels.node }} has OutOfDisk condition\\n    VALUE = {{ $value }}\\n \"" }}
          - alert: KubernetesJobFailed
            expr: kube_job_status_failed > 0
            for: 5m
            labels:
              severity: INFO
            annotations:
              summary: {{ printf "\"Kubernetes Job failed (job {{ $labels.job_name }})\"" }}
              description: {{ printf "\"  Job {{$labels.kubernetes_namespace}}/{{$labels.component}}/{{$labels.job_name}} failed to complete\\n \"" }}
          - alert: KubernetesCronjobSuspended
            expr: kube_cronjob_spec_suspend != 0
            for: 5m
            labels:
              severity: INFO
            annotations:
              summary: {{ printf "\"Kubernetes CronJob suspended (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is suspended on instance: {{ $labels.instance }}\\n    VALUE = {{ $value }}\\n \"" }}
          - alert: KubernetesPersistentvolumeclaimPending
            expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  PersistentVolumeClaim {{ $labels.instance }} {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending\\n    VALUE = {{ $value }}\\n \"" }}
          - alert: VolumeOutOfDiskSpace
            expr: kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Volume out of disk space (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"Volume is almost full (< 10%% left)\\n  Instance: {{ $labels.instance }}\\n  Namespace: {{ $labels.kubernetes_namespace }}\\n \"" }}
          - alert: VolumeFullInFourDays
            expr: 100 * (kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes) < 15 and predict_linear(kubelet_volume_stats_available_bytes[6h], 4 * 24 * 3600) < 0
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"Volume full in four days (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is expected to fill up within four days. Currently {{ $value | humanize }}%% is available.\\n  VALUE = {{ $value }}\\n \"" }}
          - alert: StatefulsetDown
            expr: (kube_statefulset_status_replicas_ready / kube_statefulset_status_replicas_current) != 1
            for: 5m
            labels:
              severity: INFO
            annotations:
              summary: {{ printf "\"StatefulSet down (instance {{ $labels.instance }})\"" }}
              description: {{ printf "\"  A StatefulSet went down\\n    Instance: {{ $labels.instance }}\\n    Namespace: {{ $labels.kubernetes_namespace }}\\n \"" }}


<<PostgreSQL>>
      - name: PostgreSQL
        rules:
          - alert: PostgreSQLMaxConnectionsReached
            expr: sum(pg_stat_activity_count) by (instance) > sum(pg_settings_max_connections) by (instance)
            for: 1m
            labels:
              severity: CRITICAL
            annotations:
              summary: {{ printf "\"{{ $labels.instance }} has maxed out Postgres connections.\"" }}
              description: {{ printf "\"  {{ $labels.instance }} is exceeding the currently configured maximum Postgres connection limit (current value: {{ $value }}s).\\n \"" }}
          - alert: PostgreSQLHighConnections
            expr: sum(pg_stat_activity_count) by (instance) > sum(pg_settings_max_connections * 0.8) by (instance)
            for: 10m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"{{ $labels.instance }} is over 80%% of max Postgres connections.\"" }}
              description: {{ printf "\"  {{ $labels.instance }} is exceeding 80%% of the currently configured maximum Postgres connection limit (current value: {{ $value }}s).\\n \"" }}
          - alert: PostgreSQLDown
            expr: pg_up != 1
            for: 1m
            labels:
              severity: CRITICAL
            annotations:
              summary: {{ printf "\"PostgreSQL is not processing queries: {{ $labels.instance }}\"" }}
              description: {{ printf "\"  {{ $labels.instance }} is rejecting query requests from the exporter, and thus probably not allowing DNS requests to work either.\\n \"" }}
          - alert: PostgreSQLSlowQueries
            expr: avg(rate(pg_stat_activity_max_tx_duration{datname!~"template.*"}[2m])) by (datname) > 2 * 60
            for: 2m
            labels:
              severity: ERROR
            annotations:
              summary: {{ printf "\"PostgreSQL high number of slow on {{ $labels.cluster }} for database {{ $labels.datname }} \"" }}
              description: {{ printf "\"  PostgreSQL high number of slow queries {{ $labels.cluster }} for database {{ $labels.datname }} with a value of {{ $value }} \\n \"" }}
          - alert: PostgreSQLQPS
            expr: avg(irate(pg_stat_database_xact_commit{datname!~"template.*"}[5m]) + irate(pg_stat_database_xact_rollback{datname!~"template.*"}[5m])) by (datname) > 10000
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"PostgreSQL high number of queries per second {{ $labels.cluster }} for database {{ $labels.datname }}\"" }}
              description: {{ printf "\"  PostgreSQL high number of queries per second on {{ $labels.cluster }} for database {{ $labels.datname }} with a value of {{ $value }}\\n \"" }}
          - alert: PostgreSQLCacheHitRatio
            expr: avg(rate(pg_stat_database_blks_hit{datname!~"template.*"}[5m]) / (rate(pg_stat_database_blks_hit{datname!~"template.*"}[5m]) + rate(pg_stat_database_blks_read{datname!~"template.*"}[5m]))) by (datname) < 0.98
            for: 5m
            labels:
              severity: WARN
            annotations:
              summary: {{ printf "\"PostgreSQL low cache hit rate on {{ $labels.cluster }} for database {{ $labels.datname }}\"" }}
              description: {{ printf "\"  PostgreSQL low on cache hit rate on {{ $labels.cluster }} for database {{ $labels.datname }} with a value of {{ $value }}\\n \"" }}